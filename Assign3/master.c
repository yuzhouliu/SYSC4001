/*  SYSC 4001, Assignment 3
 *	Student: Yuzhou Liu 100853392
 */

/* =========================================================
 * This is the master process where the producer, consumer and 
 * balancing threads are created.
 * =========================================================
 */

#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <pthread.h>
#include <sys/time.h>

#include "common_structs.h"
#include "utility.h"
#include "master.h"

int num_processes;													// Num of processes as user input
cpu_run_queue cpu_run_queues[NUM_CPU] = {0};
pthread_mutex_t queue_mutex[NUM_CPU];  		  // Protects cpu_run_queues
static int all_tasks_finished = 0;					// Flag to indicate all tasks are finsihed

int main(int argc, char *argv[])
{
	int res;
	pthread_t producer_thread, consumer_threads[NUM_CPU], balance_thread;
	int cpu_num;
	void *thread_result;

	// User input for number of processes generated by producer
	if (argc != 2) {
		fprintf(stderr, "Invalid number of parameters entered. Exiting\n");
		exit(EXIT_FAILURE);
	}
	num_processes = atoi(argv[1]);

	// Initialize the 4 queue_mutex, 1 for each CPU
	for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
		res = pthread_mutex_init(&queue_mutex[cpu_num], NULL);
		if (res != 0) {
			perror("Mutex initialization failed\n");
			exit(EXIT_FAILURE);
		}
	}

	/*-------------------------------------
	 * Create threads
	 *-------------------------------------*/
	// Create the producer thread
	res = pthread_create(&producer_thread, NULL, producer_thread_function, NULL);
	if (res != 0) {
		perror("Producer thread creation failed\n");
		exit(EXIT_FAILURE);
	}
	usleep(10000);				// Sleep for 10ms for Producer to finish

	printf("Execution of tasks begin...\n\n");
	print_task_action_header();
	
	// Create the consumer threads
	for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
		res = pthread_create(&(consumer_threads[cpu_num]), NULL, consumer_thread_function, (void *)&cpu_num);
		if (res != 0) {
			perror("Consumer thread creation failed\n");
			exit(EXIT_FAILURE);
		}
		usleep(50000);			// Sleep for 50ms to avoid mess up of cpu_num
	}

	// Create the task balancing thread
	res = pthread_create(&balance_thread, NULL, balance_run_queue_thread_function, NULL);
	if (res != 0) {
		perror("Task Balance thread creation failed\n");
		exit(EXIT_FAILURE);
	}

	/*-------------------------------------
	 * Wait for threads to finish
	 *-------------------------------------*/
	// Wait for producer to finish
	res = pthread_join(producer_thread, &thread_result);
	if( res != 0)
		perror("pthread_join failed\n");
	//printf("Producer returned\n");

	// Wait for consumers to finish
	for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
		res = pthread_join(consumer_threads[cpu_num], &thread_result);
		if(res != 0)
			perror("pthread_join failed\n");
	}

	// Wait for task balancing thread to finish
	res = pthread_join(balance_thread, &thread_result);
	if(res != 0)
		perror("pthread_join failed\n");

	printf("All done, cleaning up\n");
	for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
		pthread_mutex_destroy(&queue_mutex[cpu_num]);
	}
	
 	exit(EXIT_SUCCESS);
}

void *producer_thread_function(void *arg) 
{
	int i;
	int res;
	int curr_cpu;							// Stores the current CPU index
	int buf_tail;							// Stores the circular buffer tail
	int rq_num, sched_type, priority;
	task_struct *curr_task;

	//printf("[Producer] Thread started\n");		// debug - REMOVE

	// Seed the random number generator
	srand(time(NULL));	

	// Lock the run queues
	for(i = 0; i < NUM_CPU; i++) {
		res = pthread_mutex_lock(&queue_mutex[i]);
		if (res != 0) {
			perror("Mutex lock failed\n");
			exit(EXIT_FAILURE);
		}
	}

	for(i = 0; i < num_processes; i++) {
		// Assigns tasks to the run queue of each CPU in round robin fashion
		curr_cpu = i % 4;

		// Generates processes according to ratio:
		//  SCHED_FIFO   1/5 ratio
		//  SCHED_RR     1/5 ratio
		//  SCHED_NORMAL 3/5 ratio
		switch(i % 5) {
			case 0:	
				rq_num = 0;											// Task belongs in RQ0
				sched_type = MY_SCHED_FIFO;			// Task is SCHED_FIFO
				priority = rand()%100;					// Rand priority between 0 and 99
				break;
			case 1:
				rq_num = 0;											// Task belongs in RQ0
				sched_type = MY_SCHED_RR;				// Task is SCHED_RR
				priority = rand()%100;					// Rand priority between 0 and 99
				break;
			case 2:
			case 3:
			case 4:
				rq_num = 1;											// Task belongs in RQ1
				sched_type = MY_SCHED_NORMAL;		// Task is SCHED_NORMAL
				priority = 120; 			// Rand priority between 100 and 129
				break;
			default:
				fprintf(stderr, "[Producer] Unknown SCHED type\n");
		}
		buf_tail = cpu_run_queues[curr_cpu].rq[rq_num].tail++;
		cpu_run_queues[curr_cpu].rq[rq_num].count++;
		curr_task = &((cpu_run_queues[curr_cpu].rq[rq_num]).tasks[buf_tail]);

		curr_task->pid = i;																	// Assign PID
		curr_task->state = READY;														// Init to READY state
		curr_task->sched_type = sched_type;									// Assign schedule type (FIFO, RR, or NORMAL)
		curr_task->priority = priority;											// Assigns a priority
 		curr_task->expected_exec_time = (rand()%30+1) *100;	// Random number between 100ms to 3s
 		curr_task->remaining_exec_time = curr_task->expected_exec_time;
	}

	printf("[Producer] Printing list of tasks for each CPU...\n\n");
	print_task_list(cpu_run_queues, NUM_CPU);						// Print the list of tasks for each CPU

	// Unlock the run queues
	for(i = 0; i < NUM_CPU; i++) {
		res = pthread_mutex_unlock(&queue_mutex[i]);
		if (res != 0) {
			perror("Mutex unlock failed\n");
			exit(EXIT_FAILURE);
		}
	}

	pthread_exit(NULL);
}


void *consumer_thread_function(void *arg) 
{
	int cpu_num = *(int *)arg;
	int res;
	int time_slice, sched_type;
	int s_time, w_time;
	int rq_num, buf_index;
	task_struct *task_to_run;

	int temp_sleep_avg;
	struct timeval t1, t2;
	
  //printf("[CPU %d] Thread started\n", cpu_num);		// debug - REMOVE

  // While the all of the CPU run queues are not empty, keep looking for tasks to run
	while(!all_tasks_finished) {

		/*-----------------------------------
		 * Get the task to run
		 *-----------------------------------*/
		// Lock the appropriate run queue
		res = pthread_mutex_lock(&queue_mutex[cpu_num]);
		if (res != 0) {
			perror("Mutex lock failed\n");
			exit(EXIT_FAILURE);
		}

		// Get the next task to run by finding highest priority in a queue
		task_to_run = get_task_to_run(&(cpu_run_queues[cpu_num]), &rq_num, &buf_index);
		// If a task to run was found, then calculate time slice
		if (task_to_run != NULL) {				
			time_slice = task_to_run->time_slice = get_quantum_size(task_to_run);		// Get quantum size or time slice in ms
			sched_type = task_to_run->sched_type;																		// Gets the sched_type (FIFO, RR or NORMAL)
			task_to_run->state = RUNNING;																						// Set the state to RUNNING
			task_to_run->turnaround_started = 1;																		// Task has started to run, turnaround time starts
			temp_sleep_avg = task_to_run->sleep_avg;
		}

		// Unlock the run queue
		res = pthread_mutex_unlock(&queue_mutex[cpu_num]);
		if (res != 0) {
			perror("Mutex unlock failed\n");
			exit(EXIT_FAILURE);
		}

		// If there are no more tasks to run, continue onto next iteration
		if(task_to_run == NULL) {
			//printf("[CPU %d] No more tasks to run\n", cpu_num);			//debug - REMOVE
			sleep(1);			// Wait for a bit
			continue;
		}

		/*-----------------------------------
		 * Run the task
		 *-----------------------------------*/
		// If it is FIFO or RR then run till time slice completion
		if ( (sched_type == MY_SCHED_FIFO) || (sched_type == MY_SCHED_RR) ) {
			print_task_action(cpu_num, rq_num, task_to_run, time_slice);
			sleep( time_slice/1000 );							// sleep for the num of seconds in time_slice
			usleep( (time_slice%1000)*1000 );			// sleep for the num of ms in time_slice
		}
		// Otherwise for NORMAL, run with dynamic time slice
		else {
			s_time = w_time = 0;													// Init to 0
			s_time = rand()%(time_slice+40);							// Generate service time between 10ms to time_slice+15 (to give more chance of lowering priority)
			if (s_time > time_slice)
				s_time = time_slice;
			else if (s_time < time_slice) {										// If the process does not use up time_slice
				w_time = 900;															// Wait time of fixed 900ms
			}
			else {
				w_time = 0;
			}
			time_slice = s_time;													// used for updated accu_time_slice later on
			print_task_action(cpu_num, rq_num, task_to_run, s_time);
			
			// Run the s_time (service time)
			gettimeofday(&t1, NULL);
			sleep( s_time/1000 );
			usleep( (s_time%1000)*1000 );
			gettimeofday(&t2, NULL);
			temp_sleep_avg -= ( (t2.tv_sec-t1.tv_sec)*1000 + (t2.tv_usec-t1.tv_usec)/1000 )/100;	// Exec time in ms divide by 100

			// Emulate w_time (sleep/wait time)
			gettimeofday(&t1, NULL);
			sleep( w_time/1000 );
			usleep( (w_time%1000)*1000 );
			gettimeofday(&t2, NULL);
			temp_sleep_avg += ( (t2.tv_sec-t1.tv_sec)*1000 + (t2.tv_usec-t1.tv_usec)/1000 )/100;	// Sleep time in ms divide by 100

			// temp_sleep_avg is limited between 0 and MAX_SLEEP_AVG
			if(temp_sleep_avg < 0)
				temp_sleep_avg = 0;
			else if(temp_sleep_avg > MAX_SLEEP_AVG)
				temp_sleep_avg = MAX_SLEEP_AVG;
		}


		/*------------------------------------
		 * Update the task to reflect changes
		 *------------------------------------*/
		// Lock the appropriate run queue
		res = pthread_mutex_lock(&queue_mutex[cpu_num]);
		if (res != 0) {
			perror("Mutex lock failed\n");
			exit(EXIT_FAILURE);
		}

		// Update turnaround time for all tasks that have been started
		update_turnaround_time( &(cpu_run_queues[cpu_num]), time_slice );

		// Update the task to reflect the changes. Also update the queue if necessary
		task_to_run->accu_time_slice += time_slice;
		task_to_run->remaining_exec_time = task_to_run->expected_exec_time - task_to_run->accu_time_slice;
		task_to_run->last_cpu = cpu_num;
		// If sched_type is NORMAL, adjust the dynamic priority
		if(sched_type == MY_SCHED_NORMAL)
			task_to_run->priority = max(100, min(task_to_run->priority - temp_sleep_avg+5, 139));
		
		// If task is finished
		if(task_to_run->remaining_exec_time <= 0) {
			task_to_run->state = FINISHED;
			print_task_action(cpu_num, rq_num, task_to_run, 0);
			delete_task_from_queue(&(cpu_run_queues[cpu_num]), rq_num, buf_index);
			task_to_run = NULL;
		}
		else {													// Task not finished, put back in queue
			task_to_run->state = READY;

			// If sched_type is NORMAL and putting back into queue, check if priority places task in RQ0 or RQ1
			if( (task_to_run->priority >= 130) && (rq_num == 1) ) {
				task_to_run = move_task_from_rqSrc_to_rqDest(2, 1, &(cpu_run_queues[cpu_num]), buf_index);			// Move task from RQ1 to RQ2
				rq_num = 2;
			}
			else if ( (task_to_run->priority < 130) && (rq_num == 2) ) {
				task_to_run = move_task_from_rqSrc_to_rqDest(1, 2, &(cpu_run_queues[cpu_num]), buf_index);			// Move task from RQ2 to RQ1
				rq_num = 1;
			}
			print_task_action(cpu_num, rq_num, task_to_run, 0);
		}

		// Unlock the run queue
		res = pthread_mutex_unlock(&queue_mutex[cpu_num]);
		if (res != 0) {
			perror("Mutex unlock failed\n");
			exit(EXIT_FAILURE);
		}
	}

  pthread_exit(NULL);
}

void *balance_run_queue_thread_function(void *arg)
{
	int i;
	int res;
	int cpu_num;
	int num_tasks[NUM_CPU] = {0};					// Stores total number of tasks for each CPU
	int total_tasks;											// Stores total number of tasks across all CPUs
	cpu_run_queue curr_run_queue;
	
  //printf("[Task Balance] Thread started\n");		// debug - REMOVE

	while (!all_tasks_finished) {
		sleep(2);
		total_tasks = 0;

		// Lock all of the cpu run queues
		for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
			res = pthread_mutex_lock(&queue_mutex[cpu_num]);
			if (res != 0) {
				perror("Mutex lock failed\n");
				exit(EXIT_FAILURE);
			}
		}

		// Find the number of tasks per CPU
		for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
			num_tasks[cpu_num] = 0;

			curr_run_queue = cpu_run_queues[cpu_num];
			for (i = 0; i < NUM_RQ; i++) {
				num_tasks[cpu_num] += curr_run_queue.rq[i].count;
			}
		}

		// Unlock the run queue
		for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
			res = pthread_mutex_unlock(&queue_mutex[cpu_num]);
			if (res != 0) {
				perror("Mutex unlock failed\n");
				exit(EXIT_FAILURE);
			}
		}

		printf("\n[Task Balancer] ");
		for(cpu_num = 0; cpu_num < NUM_CPU; cpu_num++) {
			total_tasks += num_tasks[cpu_num];
			//debug
			printf("CPU%d: <%d>tasks  ", cpu_num, num_tasks[cpu_num]);
		}
		printf("\n\n");

		if(total_tasks == 0)
			all_tasks_finished = 1;
	}
	pthread_exit(NULL);
}
